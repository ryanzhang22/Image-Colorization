{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython import display\n",
    "import torch.nn.functional as F \n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "import torch.utils.tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter       \n",
    "%matplotlib inline \n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(model):\n",
    "    if type(model) in [nn.Conv2d, nn.ConvTranspose2d, nn.Linear]:\n",
    "        nn.init.xavier_normal_(model.weight.data)\n",
    "        nn.init.constant_(model.bias.data, 0.)\n",
    "\n",
    "class Color_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Color_model, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            # conv1\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 64),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 2, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 64))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            # conv2\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 128),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 2, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 128))\n",
    "            # conv3\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 256),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 256),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 2, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 256))\n",
    "            # conv4\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 1, dilation= 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 512),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1, dilation= 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 512),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1, dilation= 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 512))\n",
    "            # conv5\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 2, dilation = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 512),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 2, dilation = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 512),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 2, dilation = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 512))\n",
    "            # conv6\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 2, dilation = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 512),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 2, dilation = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 512),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 2, dilation = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 512))\n",
    "            # conv7\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 512),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 512),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 512))\n",
    "            # conv8\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor = 2.0),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 1, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 256),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1, padding = 1, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 256),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1, padding = 1, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 256))\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor = 2.0),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 1, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 128),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 1, padding = 1, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 128),\n",
    "            nn.Conv2d(in_channels = 128, out_channels =64, kernel_size = 3, stride = 1, padding = 1, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 64))\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor = 2.0),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 1, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 32),\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 1, padding = 1, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 32),\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 2, kernel_size = 3, stride = 1, padding = 1, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features = 2))\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, gray_image):\n",
    "        features = self.layer1(gray_image)\n",
    "        features = self.layer2(features) \n",
    "        features = self.layer3(features) \n",
    "        features = self.layer4(features)\n",
    "        features = self.layer5(features)\n",
    "        features = self.layer6(features)  \n",
    "        features = self.layer7(features)  \n",
    "        features = self.layer8(features) \n",
    "        features = self.layer9(features) \n",
    "        features = self.layer10(features) \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Places(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = np.load(imgLab.npy)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        imgLab = self.data[idx]\n",
    "        imgGrey = imgLab[:, :, 0]\n",
    "        imgAB = imgLab[:, :, 1:]\n",
    "        imgGrey = torch.from_numpy(np.expand_dims(imgGrey, 0))\n",
    "        \n",
    "        imgAB = torch.from_numpy(imgAB).permute(2, 0, 1)\n",
    "        return (imgGrey, imgAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss with custom gaussian filter\n",
    "def cust_loss(output, target):  \n",
    "    copy = output.clone()\n",
    "#     maskA = 2 * np.exp(-(copy[:, 0, :, :].detach().cpu() - 1) * (copy[:, 0, :, :].detach().cpu() - 1) * 1/0.2) + 1\n",
    "#     maskB = 2 * np.exp(-(copy[:, 1, :, :].detach().cpu() - .5) * (copy[:, 1, :, :].detach().cpu() - .5) * 1/0.07) + 1\n",
    "    sub = (target - output)\n",
    "#     sub[:, 0, :, :] = sub[:, 0, :, :] * maskA.cuda()\n",
    "#     sub[:, 1, :, :] = sub[:, 1, :, :] * maskB.cuda()\n",
    "    loss = torch.mean((sub)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = .005\n",
    "momentum=0.9\n",
    "epochs = 50000\n",
    "batchSize = 12\n",
    "writer = SummaryWriter() \n",
    "\n",
    "net = Color_model()\n",
    "optimizer = optim.Adam(net.parameters(), lr = eta)\n",
    "net = net.float()\n",
    "net = net.cuda()\n",
    "\n",
    "lossFreq = 20\n",
    "validFreq = 50\n",
    "saveFreq = 5\n",
    "startEpoch = 1\n",
    "\n",
    "print(\"Constructing Data\")\n",
    "\n",
    "train_Set = Places()\n",
    "\n",
    "indices = list(range(len(train_Set)))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "split = int(len(train_Set) * 0.85)\n",
    "trainIdx = indices[:split]\n",
    "validIdx = indices[split:]\n",
    "\n",
    "print(\"Random Sampling\")\n",
    "\n",
    "train_sampler = SubsetRandomSampler(trainIdx)\n",
    "valid_sampler = SubsetRandomSampler(validIdx)\n",
    "\n",
    "trainSet = torch.utils.data.DataLoader(train_Set, batch_size=batchSize, sampler = train_sampler, pin_memory=True, num_workers = 4)\n",
    "validSet = torch.utils.data.DataLoader(train_Set, batch_size=batchSize, sampler = valid_sampler, pin_memory=True, num_workers = 4)\n",
    "\n",
    "print(\"BEGIN TRAINING, NUM IMAGES IN TRAIN/VALID SET:\", len(trainIdx))\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "count = 0\n",
    "for i in range(startEpoch, epochs + startEpoch):\n",
    "    for batch_idx, (data) in enumerate(trainSet):\n",
    "        net.train()\n",
    "        X_batch = Variable(data[0]).cuda()\n",
    "        Y_batch = Variable(data[1]).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = net(X_batch.float())\n",
    "        \n",
    "        loss_mse = cust_loss(pred, Y_batch.float())\n",
    "        \n",
    "        count+=1\n",
    "        \n",
    "        # Record training loss from each epoch into the writer\n",
    "        writer.add_scalar('Batch MSE Train/Loss', loss_mse.item(), count)\n",
    "        writer.flush()\n",
    "        \n",
    "        loss_mse.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if count % lossFreq == 0:\n",
    "            print(\"Epoch: \", i, \"Batch:\", batch_idx + 1, \"Loss: \", loss_mse.item())\n",
    "            num = pred[0].detach().cpu().permute(1, 2, 0).numpy() \n",
    "            disp = np.append(X_batch[0].reshape(224, 224, 1).cpu(), num, axis = 2) * [100.0, 255.0, 255.0] - [0, 128, 128]\n",
    "            plt.imshow(lab2rgb(disp))\n",
    "            plt.show()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data) in enumerate(validSet):\n",
    "            net.eval()\n",
    "            X_valid = Variable(data[0]).cuda()\n",
    "            Y_valid = Variable(data[1]).cuda()\n",
    "\n",
    "            predValid = net(X_valid.float())\n",
    "            lossValid = F.mse_loss(predValid, Y_valid.float()).item()\n",
    "            \n",
    "            writer.add_scalar('Valid Loss', lossValid, i)\n",
    "            writer.flush()\n",
    "\n",
    "        print(\"Epoch: \", i, \"Batch:\", batch_idx + 1, \"Valid Loss: \", lossValid)\n",
    "        num = predValid[0].cpu().permute(1, 2, 0).data.numpy()\n",
    "        img_temp = X_valid[0].cpu().reshape(224, 224, 1)\n",
    "\n",
    "        disp = np.append(img_temp, num, axis = 2) * [100.0, 255.0, 255.0] - [0, 128, 128]\n",
    "        disp = lab2rgb(disp)\n",
    "\n",
    "        plt.imshow(disp)\n",
    "        plt.show()\n",
    "\n",
    "    if (i % saveFreq == 0):\n",
    "        PATH = \"Models/\" + str(i) + \"ckpt.pt\"\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': i,\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss_mse.item(),\n",
    "            }, PATH)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
